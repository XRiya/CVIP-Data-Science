{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:22:43.767044Z","iopub.execute_input":"2023-07-08T05:22:43.768018Z","iopub.status.idle":"2023-07-08T05:23:01.230033Z","shell.execute_reply.started":"2023-07-08T05:22:43.767975Z","shell.execute_reply":"2023-07-08T05:23:01.228252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom scipy.io import wavfile\nimport os.path\nimport IPython.display\nimport seaborn as sns\nimport librosa\nimport librosa.display\nimport soundfile\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras import utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten, BatchNormalization\nfrom keras import optimizers\n\nimport warnings","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://user-images.githubusercontent.com/39909903/91180489-9fe39400-e69c-11ea-9968-9adf6741d595.jpg)","metadata":{}},{"cell_type":"markdown","source":"# <center>üòÄüòêüò≠ Speech Emotion Detection üò≠üòêüòÄ</center>","metadata":{}},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"image_dir = Path('../input/speech-emotion-recognition-en/Crema')","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:23:24.035337Z","iopub.execute_input":"2023-07-08T05:23:24.036724Z","iopub.status.idle":"2023-07-08T05:23:24.043098Z","shell.execute_reply.started":"2023-07-08T05:23:24.036671Z","shell.execute_reply":"2023-07-08T05:23:24.041685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepaths = list(image_dir.glob(r'**/*.wav'))","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:23:25.238824Z","iopub.execute_input":"2023-07-08T05:23:25.239277Z","iopub.status.idle":"2023-07-08T05:23:36.981100Z","shell.execute_reply.started":"2023-07-08T05:23:25.239243Z","shell.execute_reply":"2023-07-08T05:23:36.979873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(map(lambda x: os.path.split(x)[1].split('_')[2], filepaths))","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:23:36.983626Z","iopub.execute_input":"2023-07-08T05:23:36.984428Z","iopub.status.idle":"2023-07-08T05:23:37.037449Z","shell.execute_reply.started":"2023-07-08T05:23:36.984386Z","shell.execute_reply":"2023-07-08T05:23:37.035920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set(labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:23:37.039577Z","iopub.execute_input":"2023-07-08T05:23:37.040409Z","iopub.status.idle":"2023-07-08T05:23:37.070941Z","shell.execute_reply.started":"2023-07-08T05:23:37.040364Z","shell.execute_reply":"2023-07-08T05:23:37.069826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These correspond to the emotions:\n\n* ANG: Anger üò°\n* DIS: Disgust ü§¢\n* FEA: Fear üò±\n* HAP: Happiness üòÄ\n* NEU: Neutral üòê\n* SAD: Sadness üò≠","metadata":{}},{"cell_type":"code","source":"filepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\naudio_df = pd.concat([filepaths, labels], axis=1)\naudio_df","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:23:43.404243Z","iopub.execute_input":"2023-07-08T05:23:43.404725Z","iopub.status.idle":"2023-07-08T05:23:43.481478Z","shell.execute_reply.started":"2023-07-08T05:23:43.404686Z","shell.execute_reply":"2023-07-08T05:23:43.480315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Visualising Data","metadata":{}},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(12,8)})\nsns.set_style('darkgrid')\nsns.histplot(labels, color='#4FAEB0')","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:23:45.811093Z","iopub.execute_input":"2023-07-08T05:23:45.811584Z","iopub.status.idle":"2023-07-08T05:23:46.345608Z","shell.execute_reply.started":"2023-07-08T05:23:45.811547Z","shell.execute_reply":"2023-07-08T05:23:46.344487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_arrays = []\n\nfor i in audio_df['Filepath']:\n    x, sr = librosa.load(i, sr=44100)\n    audio_arrays.append(x)\n    \naudio_df['Arrays'] = audio_arrays","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:25:53.734173Z","iopub.execute_input":"2023-07-08T05:25:53.734672Z","iopub.status.idle":"2023-07-08T05:27:27.807786Z","shell.execute_reply.started":"2023-07-08T05:25:53.734637Z","shell.execute_reply":"2023-07-08T05:27:27.806515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_df","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:27:27.809688Z","iopub.execute_input":"2023-07-08T05:27:27.811239Z","iopub.status.idle":"2023-07-08T05:27:27.845996Z","shell.execute_reply.started":"2023-07-08T05:27:27.811183Z","shell.execute_reply":"2023-07-08T05:27:27.844452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2><span class=\"label label-default\" style=\"background-color:#C00808; color:white;\">üí• ANGER üí•</span></h2>","metadata":{}},{"cell_type":"code","source":"angfile = audio_df[audio_df['Label'] == 'ANG']['Filepath']\nangarray = audio_df[audio_df['Label'] == 'ANG']['Arrays']\n\nplt.figure(figsize=(12, 4))\nplt.plot(angarray.iloc[0], color='#C00808')\nplt.xlabel('Sample')\nplt.ylabel('Amplitude')\nplt.title('Waveform')\nplt.show()\n\nIPython.display.Audio(angfile.iloc[0])\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:28:29.215350Z","iopub.execute_input":"2023-07-08T05:28:29.215809Z","iopub.status.idle":"2023-07-08T05:28:29.785053Z","shell.execute_reply.started":"2023-07-08T05:28:29.215779Z","shell.execute_reply":"2023-07-08T05:28:29.783606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2><span class=\"label label-default\" style=\"background-color:#804E2D; color:white;\"> ü§¢ DISGUST ü§¢ </span></h2>","metadata":{}},{"cell_type":"code","source":"disfile = audio_df[audio_df['Label'] == 'DIS']['Filepath']\ndisarray = audio_df[audio_df['Label'] == 'DIS']['Arrays']\n\nplt.figure(figsize=(12, 4))\nlibrosa.display.waveshow(disarray.iloc[0], color='#804E2D')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.title('Waveform')\nplt.show()\n\nIPython.display.Audio(disfile.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:28:32.830561Z","iopub.execute_input":"2023-07-08T05:28:32.830999Z","iopub.status.idle":"2023-07-08T05:28:33.590133Z","shell.execute_reply.started":"2023-07-08T05:28:32.830968Z","shell.execute_reply":"2023-07-08T05:28:33.588949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2><span class=\"label label-default\" style=\"background-color:#7D55AA; color:white; \"> üëª FEAR üëª </span></h2>","metadata":{}},{"cell_type":"code","source":"feafile = audio_df[audio_df['Label'] == 'FEA']['Filepath']\nfeaarray = audio_df[audio_df['Label'] == 'FEA']['Arrays']\n\nplt.figure(figsize=(12, 4))\nplt.plot(feaarray.iloc[0], color='#7D55AA')\nplt.xlabel('Sample')\nplt.ylabel('Amplitude')\nplt.title('Waveform')\nplt.show()\n\nIPython.display.Audio(feafile.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:28:36.973446Z","iopub.execute_input":"2023-07-08T05:28:36.974279Z","iopub.status.idle":"2023-07-08T05:28:37.463184Z","shell.execute_reply.started":"2023-07-08T05:28:36.974178Z","shell.execute_reply":"2023-07-08T05:28:37.461785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2><span class=\"label label-default\" style=\"background-color:#4CB847; color:white;\"> üòê NEUTRAL üòê </span></h2>","metadata":{}},{"cell_type":"code","source":"\nneuarray = audio_df[audio_df['Label'] == 'NEU']['Arrays']\n\nplt.figure(figsize=(14, 5))\nplt.plot(neuarray.iloc[0], color='#4CB847')\nplt.title('Waveplot')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:31:05.566307Z","iopub.execute_input":"2023-07-08T05:31:05.566688Z","iopub.status.idle":"2023-07-08T05:31:06.052372Z","shell.execute_reply.started":"2023-07-08T05:31:05.566660Z","shell.execute_reply":"2023-07-08T05:31:06.051154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <h2><span class=\"label label-default\" style=\"background-color:#478FB8; color:white;\"> ‚òî SADNESS ‚òî </span></h2>","metadata":{}},{"cell_type":"code","source":"sadarray = audio_df[audio_df['Label'] == 'SAD']['Arrays']\n\nplt.figure(figsize=(14, 5))\nplt.plot(sadarray.iloc[0], color='#478FB8')\nplt.title('Waveplot')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:33:19.411978Z","iopub.execute_input":"2023-07-08T05:33:19.412530Z","iopub.status.idle":"2023-07-08T05:33:19.977368Z","shell.execute_reply.started":"2023-07-08T05:33:19.412474Z","shell.execute_reply":"2023-07-08T05:33:19.976142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"def noise(data):\n    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n    data = data + noise_amp*np.random.normal(size=data.shape[0])\n    return data\n\ndef stretch(data, rate=0.8):\n    return librosa.effects.time_stretch(data, rate)\n\ndef pitch(data, sampling_rate, pitch_factor=0.7):\n    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:33:53.256022Z","iopub.execute_input":"2023-07-08T05:33:53.256946Z","iopub.status.idle":"2023-07-08T05:33:53.265107Z","shell.execute_reply.started":"2023-07-08T05:33:53.256890Z","shell.execute_reply":"2023-07-08T05:33:53.263598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Features","metadata":{}},{"cell_type":"code","source":"def extract_features(data):\n    # Zero Crossing Rate\n    result = np.array([])\n    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n    result = np.hstack((result, zcr))\n\n    # Chroma_stft\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr, n_fft=200).T, axis=0)\n    result = np.hstack((result, chroma_stft))     \n\n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sr, n_fft=200).T, axis=0)\n    result = np.hstack((result, mfcc))\n\n    # MelSpectogram\n    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sr, n_fft=200).T, axis=0)\n    result = np.hstack((result, mel))\n    \n    # Tonnetz\n    tonnetz = np.mean(librosa.feature.tonnetz(y=data, sr=sr).T, axis=0)\n    result = np.hstack((result, tonnetz))\n    \n    return result\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:35:12.456339Z","iopub.execute_input":"2023-07-08T05:35:12.456849Z","iopub.status.idle":"2023-07-08T05:35:12.469820Z","shell.execute_reply.started":"2023-07-08T05:35:12.456816Z","shell.execute_reply":"2023-07-08T05:35:12.468085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features(data):\n    result = []\n    \n    # without augmentation\n    res1 = extract_features(data)\n    result.append(res1)\n    \n    # with noise\n    noise_data = noise(data)\n    res2 = extract_features(noise_data)\n    result.append(res2)\n    \n    # with stretching and pitching\n    new_data = stretch(data)\n    data_stretch_pitch = pitch(new_data, sr)\n    res3 = extract_features(data_stretch_pitch)\n    result.append(res3)\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:35:23.861740Z","iopub.execute_input":"2023-07-08T05:35:23.862291Z","iopub.status.idle":"2023-07-08T05:35:23.872351Z","shell.execute_reply.started":"2023-07-08T05:35:23.862252Z","shell.execute_reply":"2023-07-08T05:35:23.870638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stretch(data, rate=0.8):\n    return librosa.effects.time_stretch(data, rate)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T05:36:21.632660Z","iopub.execute_input":"2023-07-08T05:36:21.633180Z","iopub.status.idle":"2023-07-08T05:36:21.640103Z","shell.execute_reply.started":"2023-07-08T05:36:21.633145Z","shell.execute_reply":"2023-07-08T05:36:21.638135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center> <h1>Thank you</h1> </center>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}